include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"
include "../../../arch/x64/X64.Vale.InsVector.vaf"
include "X64.AES.vaf"
include "../../../thirdPartyPorts/Intel/aes/x64/X64.AESCTRplain.vaf"
include{:fstar}{:open} "Opaque_s"
include{:fstar}{:open} "Words_s"
include{:fstar}{:open} "Types_s"
include{:fstar}{:open} "Arch.Types"
include{:/*TODO*/fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "AES_s"
include{:fstar}{:open} "GCTR_s"
include{:fstar}{:open} "GCTR"
include{:fstar}{:open} "GCM_helpers"
include{:fstar}{:open} "Workarounds"
include{:fstar}{:open} "X64.Poly1305.Math"
include{:fstar}{:open} "Words.Two_s"
include{:fstar}{:open} "X64.Machine_s"
include{:fstar}{:open} "X64.Memory"
include{:fstar}{:open} "X64.Vale.State"
include{:fstar}{:open} "X64.Vale.Decls"
include{:fstar}{:open} "X64.Vale.QuickCode"
include{:fstar}{:open} "X64.Vale.QuickCodes"
include{:fstar}{:open} "X64.CPU_Features_s"

module X64.GCTR

#verbatim{:interface}{:implementation}
module GCTR = GCTR
open Opaque_s
open Words_s
open Types_s
open Arch.Types
open FStar.Seq
open AES_s
open X64.AES
open GCTR_s
open GCTR
open GCM_helpers
open Workarounds
open X64.Poly1305.Math
open Words.Two_s
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.InsVector
open X64.Vale.InsAes
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open X64.AESCTRplain
open X64.CPU_Features_s
#endverbatim

#reset-options "--z3rlimit 30"

///////////////////////////
// GCTR encryption
///////////////////////////

procedure {:quick} init_ctr()
    modifies xmm4; efl; r12;
    ensures
        xmm4 == Mkfour(1, 0, 0, 0);
{
    Pxor(xmm4, xmm4);
    PinsrdImm(xmm4, 1, 0, r12);

    lemma_quad32_xor();
}

procedure {:quick exportOnly}{:public} Inc32(inout dst:xmm, one:xmm)
    requires
        one == Mkfour(1, 0, 0, 0);
    modifies
        efl;
    ensures
        dst == inc32(old(dst), 1);
{
    Paddd(dst, one);
}

// GCTR encrypt one block
procedure {:quick}{:public} gctr_register(
    inline alg:algorithm,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    )
    lets io @= xmm1; icb_BE @= xmm7;
    reads r8; icb_BE; mem; memTaint;
    modifies
        xmm0; xmm1; xmm2; efl; r12;

    requires
        // AES reqs
        aesni_enabled;
        alg = AES_128 || alg = AES_256;
        is_aes_key_LE(alg, key);
        length(round_keys) == nr(alg) + 1;
        round_keys == key_to_round_keys_LE(alg, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret);
        buffer128_as_seq(mem, keys_b) == round_keys;
    ensures
        le_seq_quad32_to_bytes(create(1, io)) == gctr_encrypt_LE(icb_BE, le_quad32_to_bytes(old(io)), alg, key);
        io == gctr_encrypt_block(icb_BE, old(io), alg, key, 0);
{
    assert inc32(icb_BE, 0) == icb_BE;
    Mov128(xmm0, icb_BE);
    InitPshufbMask(xmm2, r12);
    Pshufb(xmm0, xmm2);
    AESEncryptBlock(alg, reverse_bytes_quad32(icb_BE), key, round_keys, keys_b);
    reveal aes_encrypt_LE_def;
    //assert xmm0 == aes_encrypt_LE(alg, key, reverse_bytes_quad32(icb_BE));

    Pxor(xmm1, xmm0);

    assert xmm1 == quad32_xor(old(xmm1), xmm0);

    // Call a helpful lemma
    gctr_encrypt_one_block(icb_BE, old(io), alg, key);
}

procedure {:quick} gctr_core(
    inline alg:algorithm,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost block_offset:nat,
    ghost old_iv:quad32,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    )
    lets in_ptr @= rax; out_ptr @= rbx; len @= rcx; icb @= xmm7; mask @= xmm8;

    reads
        r8; in_ptr; out_ptr; len; mask; memTaint;

    modifies
        rdx; r9; r10; r12; xmm0; xmm1; xmm2; xmm4; icb; mem; efl;

    requires
        // GCTR reqs
        buffers_disjoint128(in_b, out_b);
        buffers_disjoint128(keys_b, out_b);
        validSrcAddrsOffset128(mem,  in_ptr,  in_b, block_offset, len, memTaint, Secret);
        validDstAddrsOffset128(mem, out_ptr, out_b, block_offset, len, memTaint, Secret);
        in_ptr  + 16 * len < pow2_64;
        out_ptr + 16 * len < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ 256 * buffer_length(in_b) < pow2_32;
        mask == Mkfour(0x0C0D0E0F, 0x08090A0B, 0x04050607, 0x00010203);

        // GCTR
        block_offset > 0 ==> gctr_partial(alg, block_offset, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, old_iv);
        icb == inc32(old_iv, block_offset);

        // AES reqs
        aesni_enabled;
        alg = AES_128 || alg = AES_256;
        is_aes_key_LE(alg, key);
        length(round_keys) == nr(alg) + 1;
        round_keys == key_to_round_keys_LE(alg, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret);
        buffer128_as_seq(mem, keys_b) == round_keys;
    ensures
        modifies_buffer128(out_b, old(mem), mem);
        validSrcAddrsOffset128(mem, out_ptr, out_b, block_offset, len, memTaint, Secret);
        gctr_partial(alg, block_offset + len, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, old_iv);

        icb == inc32(old(icb), old(len));
        r9 == in_ptr + 16 * len;
        r10 == out_ptr + 16 * len;
{
    Mov64(rdx, 0);
    Mov64(r9, in_ptr);
    Mov64(r10, out_ptr);

    init_ctr();

    while (rdx != len)
        invariant
            //////////////////// Basic indexing //////////////////////
            0 <= rdx <= len;
            r9 == in_ptr + 16 * rdx;
            r10 == out_ptr + 16 * rdx;
            icb == inc32(old_iv, block_offset + rdx);

            //////////////////// From requires //////////////////////
            // GCTR reqs
            buffers_disjoint128(in_b, out_b);
            buffers_disjoint128(keys_b, out_b);
            validSrcAddrsOffset128(mem,  in_ptr,  in_b, block_offset, len, memTaint, Secret);
            validDstAddrsOffset128(mem, out_ptr, out_b, block_offset, len, memTaint, Secret);
            in_ptr  + 16 * len < pow2_64;
            out_ptr + 16 * len < pow2_64;

            // AES reqs
            aesni_enabled;
            alg = AES_128 || alg = AES_256;
            is_aes_key_LE(alg, key);
            length(round_keys) == nr(alg) + 1;
            round_keys == key_to_round_keys_LE(alg, key);
            r8 == buffer_addr(keys_b, mem);
            validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret);
            buffer128_as_seq(mem, keys_b) == round_keys;

            //////////////////// GCTR invariants //////////////////////
            mask == Mkfour(0x0C0D0E0F, 0x08090A0B, 0x04050607, 0x00010203);
            xmm4 == Mkfour(1, 0, 0, 0);

            //////////////////// Postcondition goals //////////////////////
            modifies_buffer128(out_b, old(mem), mem);
            validSrcAddrsOffset128(mem, out_ptr, out_b, block_offset, len, memTaint, Secret);
            gctr_partial(alg, block_offset + rdx, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, old_iv);
        decreases
            len - rdx;
    {
        Mov128(xmm0, icb);
        Pshufb(xmm0, mask);
        AESEncryptBlock(alg, reverse_bytes_quad32(icb), key, round_keys, keys_b);
        reveal aes_encrypt_LE_def;

        Load128_buffer(xmm2, r9, 0, Secret, in_b, block_offset + rdx);
        Pxor(xmm2, xmm0);
        Store128_buffer(r10, xmm2, 0, Secret, out_b, block_offset + rdx);

        Add64(rdx, 1);
        Add64(r9, 16);
        Add64(r10, 16);
        Inc32(icb, xmm4);
    }

//    // Call a helpful lemma
//    gctr_partial_completed(alg, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, icb_BE);
}

procedure {:quick} gctr_core_opt(
    inline alg:algorithm,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    )
    lets in_ptr @= rax; out_ptr @= rbx; len @= rcx; icb @= xmm7;

    reads
        r8; memTaint;

    modifies
        in_ptr; out_ptr; len; rdx; rdi; r9; r10; r12; mem; efl;
        xmm0; xmm1; xmm2; xmm3; xmm4; xmm5; xmm6; icb; xmm8; xmm9; xmm10;
        xmm12; xmm13; xmm14; xmm15;

    requires
        // GCTR reqs
        buffers_disjoint128(in_b, out_b);
        buffers_disjoint128(keys_b, out_b);
        validSrcAddrs128(mem, in_ptr, in_b, len, memTaint, Secret);
        validDstAddrs128(mem, out_ptr, out_b, len, memTaint, Secret);
        in_ptr  + 16 * len < pow2_64;
        out_ptr + 16 * len < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ 256 * buffer_length(in_b) < pow2_32;

        // AES reqs
        aesni_enabled;
        alg = AES_128 || alg = AES_256;
        is_aes_key_LE(alg, key);
        length(round_keys) == nr(alg) + 1;
        round_keys == key_to_round_keys_LE(alg, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret);
        buffer128_as_seq(mem, keys_b) == round_keys;
    ensures
        modifies_buffer128(out_b, old(mem), mem);
        validSrcAddrs128(mem, old(out_ptr), out_b, old(len), memTaint, Secret);
        gctr_partial(alg, old(len), buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, old(icb));

        icb == old(inc32(icb, len));
        r9 == old(in_ptr + 16 * len);
        r10 == old(out_ptr + 16 * len);
{
    InitPshufbMask(xmm8, r12);

    // len == # of blocks, so we need to figure out how many sets of four blocks we have
    Mov64(rdx, len);
    Shr64(rdx, 2);
    And64(len, 3);
    lemma_poly_bits64();
    //assert rdx == old(len) / 4;
    //assert len == old(len) % 4;
    ghost var num_quad_blocks := rdx;
    assert old(len) == 4 * num_quad_blocks + len;

    if (rdx > 0) {
        // TODO: Align registers to avoid all of this pointer copying
        Mov64(r9, in_ptr);
        Mov64(r10, out_ptr);
        aes_counter_loop(alg, in_b, out_b, key, round_keys, keys_b);
        Mov64(in_ptr, r9);
        Mov64(out_ptr, r10);
    }

    gctr_core(alg, in_b, out_b, 4*num_quad_blocks, old(icb), key, round_keys, keys_b);
}


#reset-options "--z3rlimit 20"
procedure {:quick}{:public} gctr_bytes_extra_work(
    inline alg:algorithm,
    ghost icb_BE:quad32,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,
    ghost orig_in_ptr:nat64,
    ghost orig_out_ptr:nat64,
    ghost num_bytes:nat
    )
    lets in_ptr @= r9; out_ptr @= r10; icb @= xmm7;
    reads
        r8; in_ptr; out_ptr; icb; memTaint;

    modifies
        rdx; r12; xmm0; xmm1; xmm2; xmm4; mem; efl;

    requires
        // GCTR reqs
        buffers_disjoint128(in_b, out_b);
        buffers_disjoint128(keys_b, out_b);
        validSrcAddrs128(mem, orig_in_ptr, in_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        validDstAddrs128(mem, orig_out_ptr, out_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        orig_in_ptr  + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        orig_out_ptr + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ buffer_length(out_b) == bytes_to_quad_size(num_bytes) /\ 256 * buffer_length(in_b) < pow2_32 /\ 4096 * num_bytes < pow2_32;

        // AES reqs
        aesni_enabled;
        alg = AES_128 || alg = AES_256;
        is_aes_key_LE(alg, key);
        length(round_keys) == nr(alg) + 1;
        round_keys == key_to_round_keys_LE(alg, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret);
        buffer128_as_seq(mem, keys_b) == round_keys;

        // Extra reqs
        let num_blocks := num_bytes / 16;
        num_bytes % 16 != 0;
        in_ptr  == orig_in_ptr  + 16 * num_blocks;
        out_ptr == orig_out_ptr + 16 * num_blocks;
        //rcx == num_bytes;
        gctr_partial(alg, num_blocks, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, icb_BE);
        icb == inc32(icb_BE, num_blocks);
    ensures
        let num_blocks := num_bytes / 16;
        validSrcAddrs128(mem, orig_out_ptr, out_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        modifies_buffer128(out_b, old(mem), mem);
            slice_work_around(buffer128_as_seq(mem, out_b), num_blocks) ==
        old(slice_work_around(buffer128_as_seq(mem, out_b), num_blocks));
        buffer128_read(out_b, num_blocks, mem) == gctr_encrypt_block(icb_BE, buffer128_read(in_b, num_blocks, mem), alg, key, num_blocks);
        xmm1 == buffer128_read(out_b, num_blocks, mem);
{
    ghost var num_blocks := num_bytes / 16;

    // Grab the last quad
    Load128_buffer(xmm2, r9, 0, Secret, in_b, num_blocks);
    assert xmm2 == buffer128_read(in_b, num_blocks, mem);
    ghost var final_quad_LE := xmm2;

    // Encrypt it
    Mov128(xmm1, xmm2);
    gctr_register(alg, key, round_keys, keys_b);

    //assert xmm1 == gctr_encrypt_block(icb, final_quad_LE, alg, key, 0);
    gctr_encrypt_block_offset(icb_BE, final_quad_LE, alg, key, num_blocks);
    //assert xmm1 == gctr_encrypt_block(icb_BE, final_quad_LE, alg, key, num_blocks);

    // Write it back out
    Store128_buffer(r10, xmm1, 0, Secret, out_b, num_blocks);
    assert buffer128_read(out_b, num_blocks, mem) == xmm1;
    //assert buffer128_read(out_b, num_blocks, mem) == gctr_encrypt_block(icb_BE, buffer128_read(in_b, num_blocks, mem), alg, key, num_blocks);
}

#reset-options "--z3rlimit 20"
procedure {:quick}{:public} gctr_bytes_extra(
    inline alg:algorithm,
    ghost icb_BE:quad32,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,
    ghost orig_in_ptr:nat64,
    ghost orig_out_ptr:nat64,
    ghost num_bytes:nat
    )
    lets in_ptr @= r9; out_ptr @= r10; icb @= xmm7;
    reads
        r8; in_ptr; out_ptr; icb; memTaint;

    modifies
        rdx; r12; xmm0; xmm1; xmm2; xmm4; mem; efl;

    requires
        // GCTR reqs
        buffers_disjoint128(in_b, out_b);
        buffers_disjoint128(keys_b, out_b);
        validSrcAddrs128(mem, orig_in_ptr, in_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        validDstAddrs128(mem, orig_out_ptr, out_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        orig_in_ptr  + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        orig_out_ptr + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ buffer_length(out_b) == bytes_to_quad_size(num_bytes) /\ 256 * buffer_length(in_b) < pow2_32 /\ 4096 * num_bytes < pow2_32;

        // AES reqs
        aesni_enabled;
        alg = AES_128 || alg = AES_256;
        is_aes_key_LE(alg, key);
        length(round_keys) == nr(alg) + 1;
        round_keys == key_to_round_keys_LE(alg, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret);
        buffer128_as_seq(mem, keys_b) == round_keys;

        // Extra reqs
        let num_blocks := num_bytes / 16;
        num_bytes % 16 != 0;
        0 < num_bytes < 16 * bytes_to_quad_size(num_bytes);
        16 * (bytes_to_quad_size(num_bytes) - 1) < num_bytes;
        in_ptr  == orig_in_ptr  + 16 * num_blocks;
        out_ptr == orig_out_ptr + 16 * num_blocks;
        //rcx == num_bytes;
        gctr_partial(alg, num_blocks, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, icb_BE);
        icb == inc32(icb_BE, num_blocks);
    ensures
        let num_blocks := num_bytes / 16;
        validSrcAddrs128(mem, orig_out_ptr, out_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        modifies_buffer128(out_b, old(mem), mem);
        let plain  := slice(le_seq_quad32_to_bytes(buffer128_as_seq(mem,  in_b)), 0, num_bytes);
        let cipher := slice(le_seq_quad32_to_bytes(buffer128_as_seq(mem, out_b)), 0, num_bytes);
        cipher == gctr_encrypt_LE(icb_BE, make_gctr_plain_LE(plain), alg, key);
        xmm1 == buffer128_read(out_b, num_blocks, mem);

// TODO: Prove this inside gctr_bytes_extra_work
        // We modified out_b, but we didn't disrupt the work that was previously done
        let     cipher_blocks := slice_work_around(buffer128_as_seq(mem,      out_b), num_blocks);
        let old_cipher_blocks := slice_work_around(buffer128_as_seq(old(mem), out_b), num_blocks);
        cipher_blocks == old_cipher_blocks;
{
    ghost var num_blocks := num_bytes / 16;
    gctr_partial_completed(alg, slice_work_around(buffer128_as_seq(mem, in_b),  num_blocks),
                           slice_work_around(buffer128_as_seq(mem, out_b), num_blocks),
                           key, icb_BE);

    gctr_bytes_extra_work(alg, icb_BE, in_b, out_b, key, round_keys, keys_b, orig_in_ptr, orig_out_ptr, num_bytes);

    gctr_partial_to_full_advanced(icb_BE,
            buffer128_as_seq(mem, in_b),
            buffer128_as_seq(mem, out_b),
            alg, key, old(num_bytes));
}

#reset-options "--z3rlimit 20"
procedure {:quick}{:public} gctr_bytes_no_extra(
    inline alg:algorithm,
    ghost icb_BE:quad32,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,
    ghost orig_in_ptr:nat64,
    ghost orig_out_ptr:nat64,
    ghost num_bytes:nat
    )
    reads mem; memTaint;

    requires
        // GCTR reqs
        buffers_disjoint128(in_b, out_b);
        buffers_disjoint128(keys_b, out_b);
        validSrcAddrs128(mem, orig_in_ptr, in_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        validDstAddrs128(mem, orig_out_ptr, out_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        orig_in_ptr  + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        orig_out_ptr + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ buffer_length(out_b) == bytes_to_quad_size(num_bytes) /\ 256 * buffer_length(in_b) < pow2_32 /\ 4096 * num_bytes < pow2_32;

        // AES reqs
        alg = AES_128 || alg = AES_256;
        is_aes_key_LE(alg, key);
        length(round_keys) == nr(alg) + 1;
        round_keys == key_to_round_keys_LE(alg, key);
//        r8 == buffer_addr(keys_b, mem);
//        validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret, memTaint, Secret);
//        buffer128_as_seq(mem, keys_b) == round_keys;

        // Extra reqs
        let num_blocks := num_bytes / 16;
        num_bytes % 16 == 0;
        gctr_partial(alg, num_blocks, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, icb_BE);
        //icb == inc32(icb_BE, num_blocks);
    ensures
        validSrcAddrs128(mem, orig_out_ptr, out_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        modifies_buffer128(out_b, old(mem), mem);
        let plain  := slice(le_seq_quad32_to_bytes(buffer128_as_seq(mem,  in_b)), 0, num_bytes);
        let cipher := slice(le_seq_quad32_to_bytes(buffer128_as_seq(mem, out_b)), 0, num_bytes);
        cipher == gctr_encrypt_LE(icb_BE, make_gctr_plain_LE(plain), alg, key);
{
    ghost var num_blocks := num_bytes / 16;
    gctr_partial_completed(alg, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, icb_BE);
//    assert buffer128_as_seq(mem, out_b) == gctr_encrypt_recursive(icb_BE, buffer128_as_seq(old(mem), in_b), alg, key, 0);
    gctr_partial_to_full_basic(icb_BE, buffer128_as_seq(old(mem), in_b), alg, key, buffer128_as_seq(mem, out_b));
//    assert le_seq_quad32_to_bytes(buffer128_as_seq(mem, out_b)) == gctr_encrypt_LE(icb_BE, make_gctr_plain_LE(le_seq_quad32_to_bytes(buffer128_as_seq(old(mem), in_b))), alg, key);
    no_extra_bytes_helper(buffer128_as_seq(mem, in_b),  old(num_bytes));
    no_extra_bytes_helper(buffer128_as_seq(mem, out_b), old(num_bytes));
//    ghost var plain  := slice_work_around(le_seq_quad32_to_bytes(buffer128_as_seq(mem,  in_b)), old(num_bytes));
//    ghost var cipher := slice_work_around(le_seq_quad32_to_bytes(buffer128_as_seq(mem, out_b)), old(num_bytes));
//    assert plain  == le_seq_quad32_to_bytes(buffer128_as_seq(mem, in_b));
//    assert cipher == le_seq_quad32_to_bytes(buffer128_as_seq(mem, out_b));
//    assert cipher == gctr_encrypt_LE(icb_BE, make_gctr_plain_LE(plain), alg, key);
}


#reset-options "--z3rlimit 20"
procedure {:quick}{:public} gctr_bytes(
    inline alg:algorithm,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    )
    lets in_ptr @= rax; out_ptr @= rbx; num_bytes @= rcx; icb @= xmm7;

    reads
        r8; memTaint;

    modifies
        rax; rbx; num_bytes; rdx; rdi; r9; r10; r11; r12; 
        xmm0; xmm1; xmm2; xmm3; xmm4; xmm5; xmm6; icb; xmm8; xmm9; xmm10;
        xmm12; xmm13; xmm14; xmm15;
        mem; efl;

    requires
        // GCTR reqs
        buffers_disjoint128(in_b, out_b);
        buffers_disjoint128(keys_b, out_b);
        validSrcAddrs128(mem, in_ptr, in_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        validDstAddrs128(mem, out_ptr, out_b, bytes_to_quad_size(num_bytes), memTaint, Secret);
        in_ptr  + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        out_ptr + 16 * bytes_to_quad_size(num_bytes) < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ buffer_length(out_b) == bytes_to_quad_size(num_bytes) /\ 256 * buffer_length(in_b) < pow2_32 /\ 4096 * num_bytes < pow2_32;

        0 < num_bytes;

        // AES reqs
        aesni_enabled;
        alg = AES_128 || alg = AES_256;
        is_aes_key_LE(alg, key);
        length(round_keys) == nr(alg) + 1;
        round_keys == key_to_round_keys_LE(alg, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, nr(alg) + 1, memTaint, Secret);
        buffer128_as_seq(mem, keys_b) == round_keys;
    ensures
        modifies_buffer128(out_b, old(mem), mem);
        validSrcAddrs128(mem, old(out_ptr), out_b, old(bytes_to_quad_size(num_bytes)), memTaint, Secret);
        let plain  := slice_work_around(le_seq_quad32_to_bytes(buffer128_as_seq(mem,  in_b)), old(num_bytes));
        let cipher := slice_work_around(le_seq_quad32_to_bytes(buffer128_as_seq(mem, out_b)), old(num_bytes));
        cipher == gctr_encrypt_LE(old(icb), make_gctr_plain_LE(plain), alg, key);
{
    lemma_poly_bits64();
    Mov64(r11, num_bytes);
    And64(r11, 15);
    assert r11 == num_bytes % 16;
    Shr64(num_bytes, 4);
    ghost var num_blocks := old(num_bytes) / 16;
    assert rcx == num_blocks;

    gctr_core_opt(alg, in_b, out_b, key, round_keys, keys_b);
    assert icb == inc32(old(icb), num_blocks);

    if (r11 == 0) {
        gctr_bytes_no_extra(alg, old(icb), in_b, out_b, key, round_keys, keys_b, old(in_ptr), old(out_ptr), old(num_bytes));
    } else {
        gctr_bytes_extra(alg, old(icb), in_b, out_b, key, round_keys, keys_b, old(in_ptr), old(out_ptr), old(num_bytes));
    }
}
